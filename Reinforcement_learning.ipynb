{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 2 버전 선택\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# 현재 model.predict() 의 속도가 느린 문제가 있어서 eager_execution을 끕니다.\n",
    "# 관련 버그 이슈 링크: https://github.com/tensorflow/tensorflow/issues/32104\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation_space)\n",
    "print(env.observation_space.low)\n",
    "print(env.observation_space.high)\n",
    "print()\n",
    "print(env.action_space)\n",
    "print()\n",
    "print(env._max_episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "score = 0\n",
    "env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(score)\n",
    "    score += reward\n",
    "    step += 1\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print('score:', score)\n",
    "print('step:', step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "gymlogger.set_level(40) #error only\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "  \n",
    "from pyvirtualdisplay import Display\n",
    "#에러 일으키면 xvfv 설치 ##윈도우에선 안먹힘\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = wrap_env(gym.make('MountainCar-v0'))\n",
    "#pyglet =1.4.0 에서 이미지 깨지는 오류 발생으로 1.3.2로 다운그래이드해야됨\n",
    "env.reset()\n",
    "\n",
    "score = 0\n",
    "step = 0\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    score += reward\n",
    "    step += 1\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print('score:', score)\n",
    "print('step:', step)\n",
    "env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "scores = []\n",
    "training_data = []\n",
    "accepted_scores = []\n",
    "required_score = -198\n",
    "\n",
    "for i in range(10000):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    env.reset()\n",
    "    score = 0\n",
    "    game_memory = []\n",
    "    previous_obs = []\n",
    "    \n",
    "    while True:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        if len(previous_obs) > 0:\n",
    "            game_memory.append([previous_obs, action])\n",
    "        \n",
    "        previous_obs = obs\n",
    "        if obs[0] > -0.2:\n",
    "            reward = 1\n",
    "        \n",
    "        score += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "    scores.append(score)\n",
    "    if score > required_score:\n",
    "        accepted_scores.append(score)\n",
    "        for data in game_memory:\n",
    "            training_data.append(data)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(scores.mean())\n",
    "print(accepted_scores)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.distplot(scores, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array([i[0] for i in training_data]).reshape(-1, 2)\n",
    "train_Y = np.array([i[1] for i in training_data]).reshape(-1, 1)\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_Y, epochs=30, batch_size=16, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], 'b-', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "scores = []\n",
    "steps = []\n",
    "actions = []\n",
    "\n",
    "for i in range(500):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    score = 0\n",
    "    step = 0\n",
    "    previous_obs = []\n",
    "    env.reset()\n",
    "\n",
    "    while True:\n",
    "        if len(previous_obs) == 0:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            logit = model.predict(np.expand_dims(previous_obs, axis=0))[0]\n",
    "            action = np.argmax(logit)\n",
    "            actions.append(action)\n",
    "        \n",
    "        obs, reward, done, info = env.step(action)\n",
    "        previous_obs = obs\n",
    "        score += reward\n",
    "        step += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    scores.append(score)\n",
    "    steps.append(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].set_title('score')\n",
    "ax[1].set_title('step')\n",
    "sns.distplot(scores, rug=True, ax=ax[0])\n",
    "sns.distplot(steps, rug=True, ax=ax[1])\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "env = wrap_env(gym.make('MountainCar-v0'))\n",
    "env.reset()\n",
    "\n",
    "score = 0\n",
    "step = 0\n",
    "previous_obs = []\n",
    "while True:\n",
    "    if len(previous_obs) == 0:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        logit = model.predict(np.expand_dims(previous_obs, axis=0))[0]\n",
    "#         logit = logit.astype(float)\n",
    "#         logit = logit / logit.sum()\n",
    "#         prob = np.random.multinomial(1, logit)\n",
    "#         action = np.argmax(prob)\n",
    "        action = np.argmax(logit)\n",
    "    \n",
    "    obs, reward, done, info = env.step(action)\n",
    "    previous_obs = obs\n",
    "    score += reward\n",
    "    step += 1\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print('score:', score)\n",
    "print('step:', step)\n",
    "env.close()\n",
    "show_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
